{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da444281",
   "metadata": {},
   "source": [
    "Name: `Vishal Haswani`\\\n",
    "Reg. No: `19BCI0181`\\\n",
    "Faculty: `Sharmila Banu K.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112e932a",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c661d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da99aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL1 = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a5881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = request.urlopen(URL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef4d5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = res.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffec00b",
   "metadata": {},
   "source": [
    "# Tokenizing Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4e3307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbbd8d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'Pride', 'and', 'prejudice', ',', 'by', 'Jane', 'Austen', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', '.', 'Title', ':', 'Pride', 'and', 'prejudice', 'Author', ':', 'Jane', 'Austen', 'Release', 'Date', ':', 'November', '12', ',', '2022', '[', 'eBook', '#', '1342', ']', 'Language', ':', 'English', 'Produced', 'by', ':', 'Chuck', 'Greif', 'and', 'the', 'Online', 'Distributed', 'Proofreading', 'Team', 'at', 'http', ':', '//www.pgdp.net', '(', 'This', 'file', 'was', 'produced', 'from', 'images', 'available', 'at', 'The', 'Internet', 'Archive', ')', '*', '*', '*', 'START', 'OF', 'THE', 'PROJECT', 'GUTENBERG', 'EBOOK', 'PRIDE', 'AND', 'PREJUDICE', '*', '*', '*', '[', 'Illustration', ':', 'GEORGE', 'ALLEN', 'PUBLISHER', '156', 'CHARING', 'CROSS', 'ROAD', 'LONDON', 'RUSKIN', 'HOUSE', ']', '[', 'Illustration', ':', '_Reading', 'Jane', 'â€™', 's', 'Letters._', '_Chap', '34._', ']', 'PRIDE', '.', 'and', 'PREJUDICE', 'by', 'Jane', 'Austen', ',', 'with']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbbb59d",
   "metadata": {},
   "source": [
    "# Stemmers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722fcd07",
   "metadata": {},
   "source": [
    "## Examples of Different Stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d0e3b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "porter.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6237675e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lancaster = LancasterStemmer()\n",
    "lancaster.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cc9211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "reg_ing = RegexpStemmer('ing')\n",
    "print(reg_ing.stem('walking'))\n",
    "print(reg_ing.stem('singing')) # can use 'ing$' for better results in stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3af718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teng\n",
      "tien\n",
      "tien\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer('spanish')\n",
    "# should return \"tener\" for all below words\n",
    "print(snowball.stem('tengo'))\n",
    "print(snowball.stem('tienes'))\n",
    "print(snowball.stem('tiene'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5b9025",
   "metadata": {},
   "source": [
    "## Applying The Stemmer on Tokenized Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3746999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pride', 'prid'), ('prejudice', 'prejud'), ('Jane', 'jan'), ('Austen', 'aust'), ('This', 'thi'), ('use', 'us'), ('anyone', 'anyon'), ('anywhere', 'anywh'), ('United', 'unit'), ('States', 'stat'), ('other', 'oth'), ('parts', 'part'), ('restrictions', 'restrict'), ('whatsoever', 'whatsoev'), ('copy', 'cop'), ('give', 'giv'), ('re-use', 're-us'), ('under', 'und'), ('terms', 'term'), ('License', 'licens'), ('included', 'includ'), ('this', 'thi'), ('online', 'onlin'), ('are', 'ar'), ('located', 'loc'), ('United', 'unit'), ('States', 'stat'), ('will', 'wil'), ('have', 'hav'), ('laws', 'law'), ('where', 'wher'), ('are', 'ar'), ('located', 'loc'), ('before', 'bef'), ('using', 'us'), ('this', 'thi'), ('Title', 'titl'), ('Pride', 'prid'), ('prejudice', 'prejud'), ('Author', 'auth'), ('Jane', 'jan'), ('Austen', 'aust'), ('Release', 'releas'), ('Date', 'dat'), ('November', 'novemb'), ('Language', 'langu'), ('English', 'engl'), ('Produced', 'produc'), ('Greif', 'gre'), ('Online', 'onlin'), ('Distributed', 'distribut'), ('Proofreading', 'proofread'), ('This', 'thi'), ('file', 'fil'), ('produced', 'produc'), ('images', 'im'), ('available', 'avail'), ('Archive', 'arch'), ('PRIDE', 'prid'), ('PREJUDICE', 'prejud'), ('Illustration', 'illust'), ('GEORGE', 'georg'), ('ALLEN', 'al'), ('PUBLISHER', 'publ'), ('CHARING', 'char'), ('HOUSE', 'hous'), ('Illustration', 'illust'), ('Jane', 'jan'), ('PRIDE', 'prid'), ('PREJUDICE', 'prejud'), ('Jane', 'jan'), ('Austen', 'aust')]\n"
     ]
    }
   ],
   "source": [
    "stemmed_text = [lancaster.stem(word) for word in tokens]\n",
    "\n",
    "# Comparing the pesults with orignal text\n",
    "print([(tokens[i], stemmed_text[i]) for i in range(200) if stemmed_text[i] != tokens[i].lower()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e1826",
   "metadata": {},
   "source": [
    "## Example of Stemming using Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce09c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8f6a9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('am', pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dcb21ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('mice'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0e74399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "better\n",
      "best\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('good'))\n",
    "print(lemma.lemmatize('better'))\n",
    "print(lemma.lemmatize('best'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0d2a00",
   "metadata": {},
   "source": [
    "<center><h1>Thank you</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
